{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e7aed5-0e69-40e9-9d4e-2d61cfd468d4",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dece984f-2a3a-4cfa-9472-ca2dc9c0f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f59be8-e4a0-4cf4-b238-5294f6c3087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'm having fun learning NLP, starting with the basics of NLTK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b20db46-7a76-4898-be6c-64008b69ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b68ae2d-4bf7-43b5-b382-f4f37651cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " \"'m\",\n",
       " 'having',\n",
       " 'fun',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " ',',\n",
       " 'starting',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'NLTK']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159c156-dffd-4487-80e0-7a39e9de6f36",
   "metadata": {},
   "source": [
    "# Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b43239-4327-4594-9c62-1e14ab361c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b995af-4d44-4da2-9ac0-f2c7d462f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee72933-aeb1-45dc-a84b-44c57d56a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "txt = \"Why is the sky blue? Why didn't you call me? Why didn't I think of that? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "525eb886-693f-4834-b3cf-21ef8c5d447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "words = word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5731ab75-a890-49e9-8f12-e6ae4bedd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f68c45-0d2f-494a-8e60-b778888dbad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Why', 'sky', 'blue', '?', 'Why', \"n't\", 'call', '?', 'Why', \"n't\", 'I', 'think', '?']\n"
     ]
    }
   ],
   "source": [
    "filtered_words = [w for w in words if w not in stp]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4849454-d8af-4d95-a23f-1908924d961f",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1f61c-62e7-4a9f-af53-152d9d6852e1",
   "metadata": {},
   "source": [
    "**Stemming**: A rule-based or algorithmic process that chops off prefixes or suffixes from words, often resulting in non-words or invalid forms. <br>\n",
    "**Example**: \"running\", \"runner\", and \"runs\" might all be stemmed to \"run\" or \"runn\". <br>\n",
    "**Pros**: Faster and computationally less expensive than lemmatization. <br>\n",
    "**Cons**: Can produce incorrect or meaningless stems and may not consider the context of the word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07fa93-ab3e-4453-af9d-f652c5e4347e",
   "metadata": {},
   "source": [
    "**Lemmatization**: A more sophisticated process that considers the word's context and part of speech (POS) to determine its lemma (dictionary form). <br>\n",
    "**Example**:\n",
    "\"better\" would be lemmatized to \"good\", and \"studies\" would be lemmatized to \"study\". <br>\n",
    "**Pros**:\n",
    "Produces valid words and considers context, leading to more accurate text analysis. <br>\n",
    "**Cons**:\n",
    "More computationally expensive and slower than stemming. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40c0f706-9efb-4ba3-b8ce-c904f1ded16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2050201a-ee8f-4822-886b-56267fcdfbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Stem                \n",
      "Program             program             \n",
      "Programming         program             \n",
      "Programs            program             \n",
      "Programmer          programm            \n",
      "Programmed          program             \n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "sample_words = [\"Program\", \"Programming\", \"Programs\", \"Programmer\",\"Programmed\"]\n",
    "\n",
    "# Perform stemming\n",
    "print(\"{0:20}{1:20}\".format(\"Word\", \"Stem\"))\n",
    "for word in sample_words:\n",
    "    print(\"{0:20}{1:20}\".format(word, ps.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d558206-7521-4fda-acbf-b99549adb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b15828c6-f1c9-46c8-bc2c-864932d73413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Stem                \n",
      "Program             Program             \n",
      "Programming         Programming         \n",
      "Programs            Programs            \n",
      "Programmer          Programmer          \n",
      "Programmed          Programmed          \n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sample_words = [\"Program\", \"Programming\", \"Programs\", \"Programmer\",\"Programmed\"]\n",
    "\n",
    "# Perform lemmatization\n",
    "print(\"{0:20}{1:20}\".format(\"Word\", \"Stem\"))\n",
    "for word in sample_words:\n",
    "    print(\"{0:20}{1:20}\".format(word, lemmatizer.lemmatize(word, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334005de-67e7-47c0-8d4c-dc8c5a01cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
