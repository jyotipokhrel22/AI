{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ba9e8e-2de4-46f9-ac20-e5ae424558b5",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cddb53-748d-48d3-9c25-3cd6faaea9b4",
   "metadata": {},
   "source": [
    "Converting input data from its raw format (i.e. text ) into vectors of real numbers which is the format that ML models support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99523195-bde7-42d3-a3b3-7e46e7281d60",
   "metadata": {},
   "source": [
    "Vectors are essentially arrays of numbers that represent various features of the text. These arrays can be of different dimensions:<br>\n",
    "**1D Vectors**: Represent individual words (e.g., word embeddings). <br>\n",
    "**2D Vectors**: Represent sequences of words, such as sentences or documents (e.g., sentence embeddings).<br>\n",
    "**Multi-Dimensional Vectors**: Can represent more complex structures and relationships, potentially involving higher-dimensional spaces.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00117691-b8fa-4bd9-bfb1-a3f2027cf874",
   "metadata": {},
   "source": [
    "# Why do Vectorization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7c090-b2ff-4c36-bbff-49d3bfad9bff",
   "metadata": {},
   "source": [
    "1. Vectorization converts text into a numerical format that complex models can use to learn patterns and make predictions.<br>\n",
    "2. Vectorization captures the nuanced meanings and relationships between words. <br>\n",
    "3. It transforms messy, high-dimensional data into a structured, manageable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee7c81-e1fc-4208-b22f-5e00d1e74c7f",
   "metadata": {},
   "source": [
    "**One-Hot Encoding**: It converts each word into a vector where only one element is “hot” (set to 1) and all others are “cold” (set to 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8312ee5-5afc-4bad-9c1e-935b5dab60bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Creating the encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Sample data\n",
    "X = [['Red'], ['Green'], ['Blue']]\n",
    "\n",
    "# Fitting the encoder to the data\n",
    "enc.fit(X)\n",
    "\n",
    "# Transforming new data\n",
    "result = enc.transform([['Red']]).toarray()\n",
    "\n",
    "# Displaying the encoded result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4cefec-bfbb-4264-9ea3-7810db34c2a5",
   "metadata": {},
   "source": [
    "**Bag of words**:  The BoW model represents text by the frequency of words. It ignores grammar and word order, focusing solely on word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d552b7-775e-46e0-9ec8-c0f6c795bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enjoy' 'great' 'is' 'learning' 'love' 'nlp']\n",
      "[[0 0 0 0 1 1]\n",
      " [0 1 1 0 0 1]\n",
      " [1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\"I love NLP\", \"NLP is great\", \"I enjoy learning NLP\"]\n",
    "\n",
    "# Creation of BoW model\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69dff5-c205-4b6a-8dab-5a3026822c9d",
   "metadata": {},
   "source": [
    "**TF-IDF**: TF-IDF weighs the importance of a word in a document based on its frequency in the document and its rarity across the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb5d320-9508-40bb-b4df-42ee1f09dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enjoy' 'great' 'is' 'learning' 'love' 'nlp']\n",
      "[[0.         0.         0.         0.         0.861037   0.50854232]\n",
      " [0.         0.65249088 0.65249088 0.         0.         0.38537163]\n",
      " [0.65249088 0.         0.         0.65249088 0.         0.38537163]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# same text like previous example\n",
    "corpus = [\"I love NLP\", \"NLP is great\", \"I enjoy learning NLP\"]\n",
    "\n",
    "# Creation of TF-IDF model\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440381d-c454-436f-b45c-f791c0e21e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
